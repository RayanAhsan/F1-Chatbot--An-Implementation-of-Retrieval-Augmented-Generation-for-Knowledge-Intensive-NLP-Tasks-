# F1-Chatbot--An-Implementation-of-Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks-


## ğŸ“Œ Overview  
This project implements a **Retrieval-Augmented Generation (RAG)** chatbot fine-tuned on a **Formula 1 Q&A dataset**.  
By combining **retrieval-based search** (via FAISS index of Formula 1 Wikipedia passages) with **generative modeling** (RAG-Sequence + BART), the chatbot provides accurate and context-rich answers to Formula 1-related questions.  

---

## âœ¨ Features  
- ğŸ” **FAISS Retriever** â€“ Retrieves top-k relevant Formula 1 passages from Wikipedia.  
- ğŸ¤– **RAG-Sequence Model** â€“ Fine-tuned with Formula 1 Q&A pairs for domain-specific accuracy.  
- ğŸ’¬ **Interactive Chatbot** â€“ Answer Formula 1 questions via command line interface.  
- ğŸ“Š **Evaluation Metrics** â€“ Measures performance using EM, F1, and ROUGE.  

---

## âš™ï¸ Tech Stack  
- **Model:** `facebook/rag-sequence-nq` (fine-tuned)  
- **Tokenizer:** `RagTokenizer`, `BartTokenizer`  
- **Retriever:** FAISS-based document index  
- **Training Framework:** Hugging Face `Seq2SeqTrainer`  
- **Language:** Python  

---

## Evaluation Results 

| Metric               | Score |
| -------------------- | ----- |
| **Exact Match (EM)** | 73.0% |
| **F1 Score**         | 82.0% |

